{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save 177 Frames to ./frame/img/\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#video to frame\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Sample 1: Teacher\n",
    "# Sample 2: Teaching\n",
    "\n",
    "video_path = \"./Downloads/Obama.mp4\"\n",
    "frame_path = \"./FaceBoxes.Pytorch/data/sample/\"\n",
    "\n",
    "# video_name = os.path.basename(video_path)\n",
    "# video_name = os.path.splitext(video_name)\n",
    "# video_name = os.path.split(video_name[0])\n",
    "# video_name = video_name[1] + '_frame'\n",
    "\n",
    "# frame_path += video_name + \"/\"\n",
    "\n",
    "if not os.path.exists(frame_path):\n",
    "    os.makedirs(frame_path)\n",
    "\n",
    "vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "success, image = vidcap.read()\n",
    "\n",
    "count = 0\n",
    "while success:\n",
    "    print(\"\\rSave %d Frames to \" % count + frame_path, end=\"\")\n",
    "    \n",
    "    cv2.imwrite(frame_path + \"%05d.jpg\" % count, image)\n",
    "    success, image = vidcap.read()\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save 178 Frames to ./everybody_dance_now/datasets/test/test_frame_re/Done!\n"
     ]
    }
   ],
   "source": [
    "#image resize\n",
    "\n",
    "import numpy as np\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "\n",
    "pathOut = './everybody_dance_now/datasets/test/'\n",
    "\n",
    "pathOut += video_name + \"_re/\"\n",
    "\n",
    "if not os.path.exists(pathOut):\n",
    "    os.makedirs(pathOut)\n",
    "\n",
    "\n",
    "fps = 0.5\n",
    "frame_array = []\n",
    "files = [f for f in os.listdir(frame_path) if isfile(join(frame_path, f))]\n",
    "count = 1\n",
    "#for sorting the file names properly\n",
    "files.sort(key = lambda x: x[5:-4])\n",
    "files.sort()\n",
    "files = [f for f in os.listdir(frame_path) if isfile(join(frame_path, f))]\n",
    "#for sorting the file names properly\n",
    "files.sort(key = lambda x: x[5:-4])\n",
    "\n",
    "\n",
    "for i in range(len(files)):\n",
    "    filename=frame_path + files[i]\n",
    "    #reading each files\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    dst = cv2.resize(img, dsize=(512, 288), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    print(\"\\rSave %d Frames to \" % count + pathOut, end=\"\")\n",
    "    \n",
    "    cv2.imwrite(pathOut+files[i], dst)\n",
    "#    cv2.imwrite('%03d.png'%count, dst)\n",
    "    count += 1\n",
    "    \n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save 178 Rotation Frames to ./EDN/data/source_0824/images_ro/Done!\n"
     ]
    }
   ],
   "source": [
    "#image rotation\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "path_frame = \"./EDN/data/source_0824/images/\"\n",
    "pathout_frame = \"./EDN/data/source_0824/images_ro/\"\n",
    "\n",
    "if not os.path.exists(pathout_frame):\n",
    "    os.makedirs(pathout_frame)\n",
    "\n",
    "fps = 0.5\n",
    "frame_array = []\n",
    "files = [f for f in os.listdir(path_frame) if isfile(join(path_frame, f))]\n",
    "count = 1\n",
    "#for sorting the file names properly\n",
    "files.sort(key = lambda x: x[5:-4])\n",
    "files.sort()\n",
    "files = [f for f in os.listdir(path_frame) if isfile(join(path_frame, f))]\n",
    "#for sorting the file names properly\n",
    "files.sort(key = lambda x: x[5:-4])\n",
    "\n",
    "for i in range(len(files)):\n",
    "    filename=path_frame + files[i]\n",
    "    \n",
    "    #reading each files\n",
    "    img = cv2.imread(filename)\n",
    "    \n",
    "    \n",
    "    height, width= img.shape[:2]\n",
    "    \n",
    "    image=cv2.transpose(img)\n",
    "    image=cv2.flip(image,flipCode=1)\n",
    "    \n",
    "    print(\"\\rSave %d Rotation Frames to \" % count + pathout_frame, end=\"\")\n",
    "    \n",
    "    \n",
    "    cv2.imwrite(pathout_frame+files[i], image)\n",
    "    count += 1\n",
    "    \n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'isfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9c2be1a60f94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mframe_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_pose\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_pose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#for sorting the file names properly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-9c2be1a60f94>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mframe_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_pose\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_pose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#for sorting the file names properly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'isfile' is not defined"
     ]
    }
   ],
   "source": [
    "path_pose = \"./frame/img/\"\n",
    "pathout_pose = \"./frame/img_ro/\"\n",
    "\n",
    "if not os.path.exists(pathout_pose):\n",
    "    os.makedirs(pathout_pose)\n",
    "\n",
    "fps = 0.5\n",
    "frame_array = []\n",
    "files = [f for f in os.listdir(path_pose) if isfile(join(path_pose, f))]\n",
    "count = 1\n",
    "#for sorting the file names properly\n",
    "files.sort(key = lambda x: x[5:-4])\n",
    "files.sort()\n",
    "files = [f for f in os.listdir(path_pose) if isfile(join(path_pose, f))]\n",
    "#for sorting the file names properly\n",
    "files.sort(key = lambda x: x[5:-4])\n",
    "\n",
    "for i in range(len(files)):\n",
    "    filename=path_pose + files[i]\n",
    "    #reading each files\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    image=cv2.transpose(img)\n",
    "    image=cv2.flip(image,flipCode=1)\n",
    "    \n",
    "    print(\"\\rSave %d Rotation Poses to \" % count + pathout_pose, end=\"\")\n",
    "    \n",
    "    cv2.imwrite(pathout_pose+files[i], image)\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save 1201 Rotation Poses to ./EDN/data/target_0724/train/train_label_gray/Done!\n"
     ]
    }
   ],
   "source": [
    "##########################################GrayScale##########################################\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "path_pose = \"./EDN/data/target_0724/train/train_label/\"\n",
    "pathout_pose = \"./EDN/data/target_0724/train/train_label_gray/\"\n",
    "\n",
    "if not os.path.exists(pathout_pose):\n",
    "    os.makedirs(pathout_pose)\n",
    "\n",
    "fps = 0.5\n",
    "frame_array = []\n",
    "files = [f for f in os.listdir(path_pose) if isfile(join(path_pose, f))]\n",
    "count = 1\n",
    "#for sorting the file names properly\n",
    "files.sort(key = lambda x: x[5:-4])\n",
    "files.sort()\n",
    "files = [f for f in os.listdir(path_pose) if isfile(join(path_pose, f))]\n",
    "#for sorting the file names properly\n",
    "files.sort(key = lambda x: x[5:-4])\n",
    "\n",
    "for i in range(len(files)):\n",
    "    filename=path_pose + files[i]\n",
    "    #reading each files\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    image=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    print(\"\\rSave %d Rotation Poses to \" % count + pathout_pose, end=\"\")\n",
    "    \n",
    "    cv2.imwrite(pathout_pose+files[i], image)\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save 178 Rotation Frames to ./EDN/data/source_0824/images_pad/Done!\n"
     ]
    }
   ],
   "source": [
    "#image padding\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "path_frame = \"./EDN/data/source_0824/images_ro/\"\n",
    "pathout_frame = \"./EDN/data/source_0824/images_pad/\"\n",
    "\n",
    "if not os.path.exists(pathout_frame):\n",
    "    os.makedirs(pathout_frame)\n",
    "\n",
    "fps = 0.5\n",
    "frame_array = []\n",
    "files = [f for f in os.listdir(path_frame) if isfile(join(path_frame, f))]\n",
    "count = 1\n",
    "#for sorting the file names properly\n",
    "files.sort(key = lambda x: x[5:-4])\n",
    "files.sort()\n",
    "\n",
    "for i in range(len(files)):\n",
    "    filename=path_frame + files[i]\n",
    "    \n",
    "    #reading each files\n",
    "    img = cv2.imread(filename)\n",
    "    \n",
    "    \n",
    "    img_padding = np.zeros((854, 854, 3), dtype = np.uint8)\n",
    "    \n",
    "    img_padding[:, 187:667] = img\n",
    "    \n",
    "    print(\"\\rSave %d Rotation Frames to \" % count + pathout_frame, end=\"\")\n",
    "    \n",
    "    \n",
    "    cv2.imwrite(pathout_frame+files[i], img_padding)\n",
    "    count += 1\n",
    "    \n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save 2999 Frames to ./FaceBoxes.Pytorch/data/sample_25/\n",
      "Done!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width 854.0, height 480.0, fps 29.97002997002997\n"
     ]
    }
   ],
   "source": [
    "#Find face in video and show video\n",
    "\n",
    "#!/opt/local/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import cv2\n",
    "\n",
    "#재생할 파일 \n",
    "VIDEO_FILE_PATH = './Downloads/Obama.mp4'\n",
    "\n",
    "# 동영상 파일 열기\n",
    "cap = cv2.VideoCapture(VIDEO_FILE_PATH)\n",
    "\n",
    "#잘 열렸는지 확인\n",
    "if cap.isOpened() == False:\n",
    "    print ('Can\\'t open the video (%d)' % (VIDEO_FILE_PATH))\n",
    "    exit()\n",
    "\n",
    "titles = ['orig']\n",
    "#윈도우 생성 및 사이즈 변경\n",
    "for t in titles:\n",
    "    cv2.namedWindow(t)\n",
    "\n",
    "#재생할 파일의 넓이 얻기\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "#재생할 파일의 높이 얻기\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "#재생할 파일의 프레임 레이트 얻기\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "#total frame\n",
    "total_frame = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "duration = total_frame / fps\n",
    "\n",
    "\n",
    "start_time = 1\n",
    "end_time = 2\n",
    "\n",
    "\n",
    "\n",
    "print('width {0}, height {1}, fps {2}'.format(width, height, fps))\n",
    "\n",
    "#XVID가 제일 낫다고 함.\n",
    "#linux 계열 DIVX, XVID, MJPG, X264, WMV1, WMV2.\n",
    "#windows 계열 DIVX\n",
    "#저장할 비디오 코덱\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "#저장할 파일 이름\n",
    "filename = 'output.avi'\n",
    "\n",
    "#파일 stream 생성\n",
    "out = cv2.VideoWriter(filename, fourcc, 25, (int(width), int(height)))\n",
    "#filename : 파일 이름\n",
    "#fourcc : 코덱\n",
    "#fps : 초당 프레임 수\n",
    "#width : 넓이\n",
    "#height : 높이\n",
    "\n",
    "#얼굴 인식용\n",
    "# face_cascade = cv2.CascadeClassifier()\n",
    "# face_cascade.load('./haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "while(True):\n",
    "    #파일로 부터 이미지 얻기\n",
    "    ret, frame = cap.read()\n",
    "    #더 이상 이미지가 없으면 종료\n",
    "    #재생 다 됨\n",
    "#     if start_time > duration or end_time < duration:\n",
    "#         continue\n",
    "    \n",
    "    if frame is None:\n",
    "        break;\n",
    "\n",
    "    #얼굴인식 영상 처리\n",
    "#     grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#     blur =  cv2.GaussianBlur(grayframe,(5,5), 0)\n",
    "#     faces = face_cascade.detectMultiScale(blur, 1.8, 2, 0, (50, 50))\n",
    "\n",
    "#     #원본 이미지에 얼굴 인식된 부분 표시\n",
    "#     for (x,y,w,h) in faces:\n",
    "#         cx = int(x+(w/2))\n",
    "#         cy = int(y+(h/2))\n",
    "#         cr = int(w/2)\n",
    "#         cv2.circle(frame,(cx,cy),cr,(0,255,0),3)\n",
    "\n",
    "#     # 얼굴 인식된 이미지 화면 표시\n",
    "#     cv2.imshow(titles[0],frame)\n",
    "\n",
    "    # 인식된 이미지 파일로 저장\n",
    "    out.write(frame)\n",
    "#     fps += fps\n",
    "#     duration = total_frame / fps\n",
    "\n",
    "    #1ms 동안 키입력 대기\n",
    "#     if cv2.waitKey(1) == 27:\n",
    "#         break;\n",
    "\n",
    "print(\"Done!\")\n",
    "#재생 파일 종료\n",
    "cap.release()\n",
    "#저장 파일 종료\n",
    "out.release()\n",
    "#윈도우 종료\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0\n",
      "25.0\n",
      "26220.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "#재생할 파일 \n",
    "VIDEO_FILE_PATH = './output.avi'\n",
    "\n",
    "# 동영상 파일 열기\n",
    "cap = cv2.VideoCapture(VIDEO_FILE_PATH)\n",
    "\n",
    "total_frame = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "print(cap.get(cv2.CAP_PROP_FPS))\n",
    "cap.set(cv2.CAP_PROP_FPS, 20)\n",
    "print(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "print(total_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.3.0) /tmp/pip-req-build-o_qzfp88/opencv/modules/highgui/src/window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1fada222d03f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#Display the resulting frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_video_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' frame '\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#Set waitKey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.3.0) /tmp/pip-req-build-o_qzfp88/opencv/modules/highgui/src/window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#Get video name from user\n",
    "#Ginen video name must be in quotes, e.g. \"pirkagia.avi\" or \"plaque.avi\"\n",
    "video_name = './Downloads/Obama.mp4'\n",
    "\n",
    "#Open the video file\n",
    "cap = cv2.VideoCapture(video_name)\n",
    "\n",
    "#Set frame_no in range 0.0-1.0\n",
    "#In this example we have a video of 30 seconds having 25 frames per seconds, thus we have 750 frames.\n",
    "#The examined frame must get a value from 0 to 749.\n",
    "#For more info about the video flags see here: https://stackoverflow.com/questions/11420748/setting-camera-parameters-in-opencv-python\n",
    "#Here we select the last frame as frame sequence=749. In case you want to select other frame change value 749.\n",
    "#BE CAREFUL! Each video has different time length and frame rate. \n",
    "#So make sure that you have the right parameters for the right video!\n",
    "time_length = 30.0\n",
    "fps=25\n",
    "frame_seq = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_no = (frame_seq /(time_length*fps))\n",
    "\n",
    "#The first argument of cap.set(), number 2 defines that parameter for setting the frame selection.\n",
    "#Number 2 defines flag CV_CAP_PROP_POS_FRAMES which is a 0-based index of the frame to be decoded/captured next.\n",
    "#The second argument defines the frame number in range 0.0-1.0\n",
    "cap.set(2,frame_no);\n",
    "\n",
    "#Read the next frame from the video. If you set frame 749 above then the code will return the last frame.\n",
    "ret, frame = cap.read()\n",
    "\n",
    "#Set grayscale colorspace for the frame. \n",
    "# gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Cut the video extension to have the name of the video\n",
    "my_video_name = video_name.split(\".\")[0]\n",
    "\n",
    "#Display the resulting frame\n",
    "cv2.imshow(my_video_name+' frame '+ str(frame_seq),frame)\n",
    "\n",
    "#Set waitKey \n",
    "cv2.waitKey()\n",
    "\n",
    "#Store this frame to an image\n",
    "cv2.imwrite(my_video_name+'_frame_'+str(frame_seq)+'.jpg',frame)\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video to frame\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# Sample 1: Teacher\n",
    "# Sample 2: Teaching\n",
    "\n",
    "video_path = \"./Downloads/Obama.mp4\"\n",
    "frame_path = \"./FaceBoxes.Pytorch/data/sample_25/images\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# video_name = os.path.basename(video_path)\n",
    "# video_name = os.path.splitext(video_name)\n",
    "# video_name = os.path.split(video_name[0])\n",
    "# video_name = video_name[1] + '_frame'\n",
    "\n",
    "# frame_path += video_name + \"/\"\n",
    "\n",
    "if not os.path.exists(frame_path):\n",
    "    os.makedirs(frame_path)\n",
    "\n",
    "vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "\n",
    "fps = round(vidcap.get(cv2.CAP_PROP_FPS), 1)\n",
    "\n",
    "start_time = 10\n",
    "end_time = 20\n",
    "\n",
    "length = round((end_time - start_time) * 25)\n",
    "\n",
    "start_frame = round(start_time * fps)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "count = 0\n",
    "skip_count = 1\n",
    "\n",
    "while success:\n",
    "    success, image = vidcap.read()\n",
    "    \n",
    "    if count == length:\n",
    "        break\n",
    "    \n",
    "    if skip_count < start_frame:\n",
    "        skip_count+=1\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    elif skip_count % 6 == 0 :\n",
    "        skip_count+=1\n",
    "        continue\n",
    "    \n",
    "    cv2.imwrite(frame_path+\"%05d.jpg\" % count, image)\n",
    "    print(\"\\rSave %d Frames to \" % count + frame_path, end=\"\")\n",
    "    \n",
    "    count+=1\n",
    "    skip_count+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"\\nDone!\")\n",
    "\n",
    "subprocess.call('python ./FaceBoxes.Pytorch/test.py --dataset AFW', shell=True)\n",
    "\n",
    "\n",
    "\n",
    "# frame to video\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from os.path import isfile, join\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "out = cv2.VideoWriter('sample_video.avi', fourcc, 25.0, (512,512))\n",
    "\n",
    "path_frame = './FaceBoxes.Pytorch/data/extract/'\n",
    "\n",
    "files = [f for f in os.listdir(path_frame) if isfile(join(path_frame, f))]\n",
    "count = 1\n",
    "#for sorting the file names properly\n",
    "files.sort(key = lambda x: x[5:-4])\n",
    "files.sort()\n",
    "\n",
    "\n",
    "for i in range(len(files)):\n",
    "    \n",
    "    frame = cv2.imread(path_frame + files[i], cv2.IMREAD_COLOR)\n",
    "#     if ret:\n",
    "#         # 이미지 반전,  0:상하, 1 : 좌우\n",
    "#         frame = cv2.flip(frame, 0)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "    \n",
    "\n",
    "#     if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "#             break\n",
    "    \n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'moviepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-0bdc437c7675>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meditor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvideoclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./Downloads/Obama.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideoclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'moviepy'"
     ]
    }
   ],
   "source": [
    "#need subversion of numpy\n",
    "\n",
    "from moviepy.editor import *\n",
    "\n",
    "videoclip = VideoFileClip(\"./Downloads/Obama.mp4\")\n",
    "\n",
    "audio = videoclip.audio\n",
    "audio.write_audiofile('./Obama.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'pytube'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-0b82033456b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Need python 3.5version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytube\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYouTube\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'pytube'"
     ]
    }
   ],
   "source": [
    "#Need python 3.5version\n",
    "from pytube import YouTube\n",
    "import requests\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "workdir = './Downloads/'\n",
    "\n",
    "url = 'https://www.youtube.com/watch?v=bps3m4eFTuE'\n",
    "# workdir = os.path.dirname(os.path.realpath(__file__))\n",
    "# url = input('playlist url : ').rstrip()\n",
    "\n",
    "# if 'watch' in url:\n",
    "#     url = 'https://youtube.com/playlist?list=' + url.split('list=')[-1].split('&')[0]\n",
    "\n",
    "res = requests.get(url)\n",
    "source = res.text #Response의 바디를 source라는 변수에 저장합니다. 이는 Raw Text 입니다.\n",
    "vid_ids = [x.split('href=\"/watch?v=')[1].split('&amp;')[0] for x in source.split('\\n') if 'pl-video-title-link' in x]\n",
    "\n",
    "\n",
    "for vid in vid_ids:\n",
    "    getStr = 'https://www.youtube.com/watch?v=' + vid\n",
    "    yt = YouTube(getStr)\n",
    "    file_name = yt.title\n",
    "    print('Downloading %s' % (file_name))\n",
    "\n",
    "    yt.streams.filter(adaptive=True, file_extension='mp4', only_video=True).order_by('resolution').desc().first().download('./', 'video')\n",
    "    yt.streams.filter(adaptive=True, file_extension='mp4', only_audio=True).order_by('abr').desc().first().download('./', 'audio')\n",
    "    output = ''\n",
    "\n",
    "    result = subprocess.Popen(['ffmpeg', '-y', '-i', workdir + '/video.mp4', '-i', workdir + '/audio.mp4', workdir + '/' + file_name.replace('/', '-') + '.mp4'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    # Filename에 replace가 들어가는 이유는 \"/\" 문자가 들어갈 경우 파일이름이 아니라 디렉토리로 인식하기 떄문입니다. replace없이 바로 집어넣을 경우 문제가 발생합니다.\n",
    "    out, err = result.communicate()\n",
    "    exitcode = result.returncode\n",
    "    if exitcode != 0:\n",
    "        print(exitcode, out.decode('utf8'), err.decode('utf8'))\n",
    "    else:\n",
    "        print('Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'pytube'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-e6217c8f9c35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpytube\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'pytube'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
