{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "poses = np.load('/home/chuhk/everybody_dance_now/datasets/test/test_poses.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 91, 236],\n",
       "       [113, 228],\n",
       "       [102, 211],\n",
       "       [122, 187],\n",
       "       [148, 188],\n",
       "       [124, 245],\n",
       "       [157, 241],\n",
       "       [184, 229],\n",
       "       [169, 197],\n",
       "       [209, 189],\n",
       "       [248, 174],\n",
       "       [174, 222],\n",
       "       [214, 217],\n",
       "       [247, 235],\n",
       "       [ 87, 235],\n",
       "       [ 90, 243],\n",
       "       [ 89, 231],\n",
       "       [ 97, 249]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "model = load_model('../everybody_dance_now/pose_estimator/pose_estimator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              [(1, 46, 46, 38), (1, 46, 52311446  \n",
      "=================================================================\n",
      "Total params: 52,311,446\n",
      "Trainable params: 52,311,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "from tqdm import tqdm\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from skimage.measure import label\n",
    "from collections import OrderedDict\n",
    "from scipy.ndimage.filters import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def natural_key(string_):\n",
    "    return [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', string_) if s]\n",
    "\n",
    "\n",
    "def make_layers(block, no_relu_layers):\n",
    "    layers = []\n",
    "    for layer_name, v in block.items():\n",
    "        if 'pool' in layer_name:\n",
    "            layer = nn.MaxPool2d(kernel_size=v[0], stride=v[1],\n",
    "                                    padding=v[2])\n",
    "            layers.append((layer_name, layer))\n",
    "\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels=v[0], out_channels=v[1],\n",
    "                               kernel_size=v[2], stride=v[3],\n",
    "                               padding=v[4])\n",
    "            layers.append((layer_name, conv2d))\n",
    "\n",
    "            if layer_name not in no_relu_layers:\n",
    "                layers.append(('relu_'+layer_name, nn.ReLU(inplace=True)))\n",
    "\n",
    "        try:\n",
    "            raise ValueError(\"LAYER:\", layer_name)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return nn.Sequential(OrderedDict(layers))\n",
    "\n",
    "\n",
    "\n",
    "class BodyposeModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BodyposeModel, self).__init__()\n",
    "\n",
    "        no_relu_layers = ['conv5_5_CPM_L1', 'conv5_5_CPM_L2', 'Mconv7_stage2_L1',\\\n",
    "                          'Mconv7_stage2_L2', 'Mconv7_stage3_L1', 'Mconv7_stage3_L2',\\\n",
    "                          'Mconv7_stage4_L1', 'Mconv7_stage4_L2', 'Mconv7_stage5_L1',\\\n",
    "                          'Mconv7_stage5_L2', 'Mconv7_stage6_L1', 'Mconv7_stage6_L1']\n",
    "\n",
    "        blocks = {}\n",
    "        block0 = OrderedDict([\n",
    "            ('conv1_1', [3, 64, 3, 1, 1]),\n",
    "            ('conv1_2', [64, 64, 3, 1, 1]),\n",
    "            ('pool1_stage1', [2, 2, 0]),\n",
    "            ('conv2_1', [64, 128, 3, 1, 1]),\n",
    "            ('conv2_2', [128, 128, 3, 1, 1]),\n",
    "            ('pool2_stage1', [2, 2, 0]),\n",
    "            ('conv3_1', [128, 256, 3, 1, 1]),\n",
    "            ('conv3_2', [256, 256, 3, 1, 1]),\n",
    "            ('conv3_3', [256, 256, 3, 1, 1]),\n",
    "            ('conv3_4', [256, 256, 3, 1, 1]),\n",
    "            ('pool3_stage1', [2, 2, 0]),\n",
    "            ('conv4_1', [256, 512, 3, 1, 1]),\n",
    "            ('conv4_2', [512, 512, 3, 1, 1]),\n",
    "            ('conv4_3_CPM', [512, 256, 3, 1, 1]),\n",
    "            ('conv4_4_CPM', [256, 128, 3, 1, 1])\n",
    "        ])\n",
    "\n",
    "        block1_1 = OrderedDict([\n",
    "            ('conv5_1_CPM_L1', [128, 128, 3, 1, 1]),\n",
    "            ('conv5_2_CPM_L1', [128, 128, 3, 1, 1]),\n",
    "            ('conv5_3_CPM_L1', [128, 128, 3, 1, 1]),\n",
    "            ('conv5_4_CPM_L1', [128, 512, 1, 1, 0]),\n",
    "            ('conv5_5_CPM_L1', [512, 38, 1, 1, 0])\n",
    "        ])\n",
    "\n",
    "        block1_2 = OrderedDict([\n",
    "            ('conv5_1_CPM_L2', [128, 128, 3, 1, 1]),\n",
    "            ('conv5_2_CPM_L2', [128, 128, 3, 1, 1]),\n",
    "            ('conv5_3_CPM_L2', [128, 128, 3, 1, 1]),\n",
    "            ('conv5_4_CPM_L2', [128, 512, 1, 1, 0]),\n",
    "            ('conv5_5_CPM_L2', [512, 19, 1, 1, 0])\n",
    "        ])\n",
    "\n",
    "        blocks['block1_1'] = block1_1\n",
    "        blocks['block1_2'] = block1_2\n",
    "\n",
    "        self.model0 = make_layers(block0, no_relu_layers)\n",
    "\n",
    "        for i in range(2, 7):\n",
    "            blocks['block%d_1' % i] = OrderedDict([\n",
    "                ('Mconv1_stage%d_L1' % i, [185, 128, 7, 1, 3]),\n",
    "                ('Mconv2_stage%d_L1' % i, [128, 128, 7, 1, 3]),\n",
    "                ('Mconv3_stage%d_L1' % i, [128, 128, 7, 1, 3]),\n",
    "                ('Mconv4_stage%d_L1' % i, [128, 128, 7, 1, 3]),\n",
    "                ('Mconv5_stage%d_L1' % i, [128, 128, 7, 1, 3]),\n",
    "                ('Mconv6_stage%d_L1' % i, [128, 128, 1, 1, 0]),\n",
    "                ('Mconv7_stage%d_L1' % i, [128, 38, 1, 1, 0])\n",
    "            ])\n",
    "\n",
    "            blocks['block%d_2' % i] = OrderedDict([\n",
    "                ('Mconv1_stage%d_L2' % i, [185, 128, 7, 1, 3]),\n",
    "                ('Mconv2_stage%d_L2' % i, [128, 128, 7, 1, 3]),\n",
    "                ('Mconv3_stage%d_L2' % i, [128, 128, 7, 1, 3]),\n",
    "                ('Mconv4_stage%d_L2' % i, [128, 128, 7, 1, 3]),\n",
    "                ('Mconv5_stage%d_L2' % i, [128, 128, 7, 1, 3]),\n",
    "                ('Mconv6_stage%d_L2' % i, [128, 128, 1, 1, 0]),\n",
    "                ('Mconv7_stage%d_L2' % i, [128, 19, 1, 1, 0])\n",
    "            ])\n",
    "\n",
    "        for k in blocks.keys():\n",
    "            blocks[k] = make_layers(blocks[k], no_relu_layers)\n",
    "\n",
    "        self.model1_1 = blocks['block1_1']\n",
    "        self.model2_1 = blocks['block2_1']\n",
    "        self.model3_1 = blocks['block3_1']\n",
    "        self.model4_1 = blocks['block4_1']\n",
    "        self.model5_1 = blocks['block5_1']\n",
    "        self.model6_1 = blocks['block6_1']\n",
    "\n",
    "        self.model1_2 = blocks['block1_2']\n",
    "        self.model2_2 = blocks['block2_2']\n",
    "        self.model3_2 = blocks['block3_2']\n",
    "        self.model4_2 = blocks['block4_2']\n",
    "        self.model5_2 = blocks['block5_2']\n",
    "        self.model6_2 = blocks['block6_2']\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.model0(x)\n",
    "\n",
    "        out1_1 = self.model1_1(out1)\n",
    "        out1_2 = self.model1_2(out1)\n",
    "        out2 = torch.cat([out1_1, out1_2, out1], 1)\n",
    "\n",
    "        out2_1 = self.model2_1(out2)\n",
    "        out2_2 = self.model2_2(out2)\n",
    "        out3 = torch.cat([out2_1, out2_2, out1], 1)\n",
    "\n",
    "        out3_1 = self.model3_1(out3)\n",
    "        out3_2 = self.model3_2(out3)\n",
    "        out4 = torch.cat([out3_1, out3_2, out1], 1)\n",
    "\n",
    "        out4_1 = self.model4_1(out4)\n",
    "        out4_2 = self.model4_2(out4)\n",
    "        out5 = torch.cat([out4_1, out4_2, out1], 1)\n",
    "\n",
    "        out5_1 = self.model5_1(out5)\n",
    "        out5_2 = self.model5_2(out5)\n",
    "        out6 = torch.cat([out5_1, out5_2, out1], 1)\n",
    "\n",
    "        out6_1 = self.model6_1(out6)\n",
    "        out6_2 = self.model6_2(out6)\n",
    "\n",
    "        return out6_1, out6_2\n",
    "\n",
    "\n",
    "class HandposeModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HandposeModel, self).__init__()\n",
    "\n",
    "        no_relu_layers = ['conv6_2_CPM', 'Mconv7_stage2', 'Mconv7_stage3',\\\n",
    "                          'Mconv7_stage4', 'Mconv7_stage5', 'Mconv7_stage6']\n",
    "\n",
    "        block1_0 = OrderedDict([\n",
    "            ('conv1_1', [3, 64, 3, 1, 1]),\n",
    "            ('conv1_2', [64, 64, 3, 1, 1]),\n",
    "            ('pool1_stage1', [2, 2, 0]),\n",
    "            ('conv2_1', [64, 128, 3, 1, 1]),\n",
    "            ('conv2_2', [128, 128, 3, 1, 1]),\n",
    "            ('pool2_stage1', [2, 2, 0]),\n",
    "            ('conv3_1', [128, 256, 3, 1, 1]),\n",
    "            ('conv3_2', [256, 256, 3, 1, 1]),\n",
    "            ('conv3_3', [256, 256, 3, 1, 1]),\n",
    "            ('conv3_4', [256, 256, 3, 1, 1]),\n",
    "            ('pool3_stage1', [2, 2, 0]),\n",
    "            ('conv4_1', [256, 512, 3, 1, 1]),\n",
    "            ('conv4_2', [512, 512, 3, 1, 1]),\n",
    "            ('conv4_3', [512, 512, 3, 1, 1]),\n",
    "            ('conv4_4', [512, 512, 3, 1, 1]),\n",
    "            ('conv5_1', [512, 512, 3, 1, 1]),\n",
    "            ('conv5_2', [512, 512, 3, 1, 1]),\n",
    "            ('conv5_3_CPM', [512, 128, 3, 1, 1])\n",
    "        ])\n",
    "\n",
    "        block1_1 = OrderedDict([\n",
    "            ('conv6_1_CPM', [128, 512, 1, 1, 0]),\n",
    "            ('conv6_2_CPM', [512, 22, 1, 1, 0])\n",
    "        ])\n",
    "\n",
    "        blocks = {}\n",
    "        blocks['block1_0'] = block1_0\n",
    "        blocks['block1_1'] = block1_1\n",
    "\n",
    "        for i in range(2, 7):\n",
    "            blocks['block%d' % i] = OrderedDict([\n",
    "                ('Mconv1_stage%d' % i, [150, 128, 7, 1, 3]),\n",
    "                ('Mconv2_stage%d' % i, [128, 128, 7, 1, 3]),\n",
    "                ('Mconv3_stage%d' % i, [128, 128, 7, 1, 3]),\n",
    "                ('Mconv4_stage%d' % i, [128, 128, 7, 1, 3]),\n",
    "                ('Mconv5_stage%d' % i, [128, 128, 7, 1, 3]),\n",
    "                ('Mconv6_stage%d' % i, [128, 128, 1, 1, 0]),\n",
    "                ('Mconv7_stage%d' % i, [128, 22, 1, 1, 0])\n",
    "            ])\n",
    "\n",
    "        for k in blocks.keys():\n",
    "            blocks[k] = make_layers(blocks[k], no_relu_layers)\n",
    "\n",
    "        self.model1_0 = blocks['block1_0']\n",
    "        self.model1_1 = blocks['block1_1']\n",
    "        self.model2 = blocks['block2']\n",
    "        self.model3 = blocks['block3']\n",
    "        self.model4 = blocks['block4']\n",
    "        self.model5 = blocks['block5']\n",
    "        self.model6 = blocks['block6']\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1_0 = self.model1_0(x)\n",
    "        out1_1 = self.model1_1(out1_0)\n",
    "        concat_stage2 = torch.cat([out1_1, out1_0], 1)\n",
    "        out_stage2 = self.model2(concat_stage2)\n",
    "        concat_stage3 = torch.cat([out_stage2, out1_0], 1)\n",
    "        out_stage3 = self.model3(concat_stage3)\n",
    "        concat_stage4 = torch.cat([out_stage3, out1_0], 1)\n",
    "        out_stage4 = self.model4(concat_stage4)\n",
    "        concat_stage5 = torch.cat([out_stage4, out1_0], 1)\n",
    "        out_stage5 = self.model5(concat_stage5)\n",
    "        concat_stage6 = torch.cat([out_stage5, out1_0], 1)\n",
    "        out_stage6 = self.model6(concat_stage6)\n",
    "\n",
    "        return out_stage6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class constant_gpu:\n",
    "    def __init__(self,\n",
    "                 reshape_w=656,\n",
    "                 reshape_h=368,\n",
    "                 scale_factor=8,\n",
    "                 wrist_elbow_ratio=0.33,\n",
    "                 elbow_shoulder_dist_const=0.9,\n",
    "                 width_const=1.5):\n",
    "        self.reshape_w = torch.tensor(reshape_w, dtype=torch.long)\n",
    "        self.reshape_h = torch.tensor(reshape_h, dtype=torch.long)\n",
    "        self.scale_factor = torch.tensor(scale_factor, dtype=torch.long)\n",
    "        self.wrist_elbow_ratio = torch.tensor(wrist_elbow_ratio)\n",
    "        self.elbow_shoulder_dist_const = torch.tensor(elbow_shoulder_dist_const)\n",
    "        self.width_const = torch.tensor(width_const)\n",
    "\n",
    "        self.body_zeros = torch.zeros((8, reshape_h, reshape_w))\n",
    "        self.hand_zeros = torch.zeros((21, reshape_h, reshape_w))\n",
    "        \n",
    "\n",
    "    def pendding(self, device):\n",
    "        self.device = device\n",
    "        self.reshape_w = self.reshape_w.to(device)\n",
    "        self.reshape_h = self.reshape_h.to(device)\n",
    "        self.scale_factor = self.scale_factor.to(device)\n",
    "        self.wrist_elbow_ratio = self.wrist_elbow_ratio.to(device)\n",
    "        self.elbow_shoulder_dist_const = self.elbow_shoulder_dist_const.to(device)\n",
    "        self.width_const = self.width_const.to(device)\n",
    "\n",
    "        self.body_zeros = self.body_zeros.to(device)\n",
    "        self.hand_zeros = self.hand_zeros.to(device)\n",
    "\n",
    "\n",
    "\n",
    "def parsing_body_heatmap(all_body_peaks, idx, heatmap, const):\n",
    "    heatmap = torch.where(heatmap <= 0.1, const.body_zeros, heatmap)\n",
    "\n",
    "    x_val, x = heatmap.max(1)[0].max(1)\n",
    "    y_val, y = heatmap.max(2)[0].max(1)\n",
    "\n",
    "    x = torch.where(x_val == 0, x_val.long(), x)\n",
    "    y = torch.where(x_val == 0, y_val.long(), y)\n",
    "    \n",
    "    x[x_val < 0.20] = 0\n",
    "    y[y_val < 0.20] = 0\n",
    "\n",
    "    all_body_peaks[idx][:, 0] = x\n",
    "    all_body_peaks[idx][:, 1] = y\n",
    "\n",
    "    \n",
    "\n",
    "def parsing_hand_heatmap(all_hand_peaks, idx, heatmap, const):\n",
    "    c, h, w = heatmap.shape\n",
    "\n",
    "    heatmap = torch.where(heatmap <= 0.04, const.hand_zeros[:c, :h, :w], heatmap) \n",
    "    \n",
    "    x_val, x = heatmap.max(1)[0].max(1) \n",
    "    y_val, y = heatmap.max(2)[0].max(1) \n",
    "\n",
    "    x = torch.where(x_val == 0, x_val.long(), x) \n",
    "    y = torch.where(y_val == 0, y_val.long(), y)\n",
    "    \n",
    "    x[x_val < 0.30] = 0\n",
    "    y[y_val < 0.30] = 0\n",
    "    \n",
    "    det_num = torch.nonzero(x).shape[0]\n",
    "    \n",
    "    if det_num < 15:\n",
    "        x[x_val < 1.0] = 0\n",
    "        y[y_val < 1.0] = 0\n",
    "\n",
    "    all_hand_peaks[idx][:, 0] = x\n",
    "    all_hand_peaks[idx][:, 1] = y\n",
    "\n",
    "\n",
    "    \n",
    "def hand_detect(body_peaks, const):\n",
    "    detect_result = []\n",
    "    hands = []\n",
    "\n",
    "    x1, y1 = body_peaks[5][:2]  # l_shoulder_idx\n",
    "    x2, y2 = body_peaks[6][:2]  # l_elbow_idx\n",
    "    x3, y3 = body_peaks[7][:2]  # l_wrist_idx\n",
    "    hands.append([x1, y1, x2, y2, x3, y3, True])\n",
    "\n",
    "    x1, y1 = body_peaks[2][:2]  # r_shoulder_idx\n",
    "    x2, y2 = body_peaks[3][:2]  # r_elbow_idx\n",
    "    x3, y3 = body_peaks[4][:2]  # r_wrist_idx\n",
    "    hands.append([x1, y1, x2, y2, x3, y3, False])\n",
    "\n",
    "    for x1, y1, x2, y2, x3, y3, is_left in hands:\n",
    "        x = x3 + const.wrist_elbow_ratio * (x3 - x2)\n",
    "        y = y3 + const.wrist_elbow_ratio * (y3 - y2)\n",
    "\n",
    "        wrist_elbow_dist = torch.sqrt(\n",
    "            (x3 - x2).float() ** 2 + (y3 - y2).float() ** 2)\n",
    "        elbow_shoulder_dist = torch.sqrt(\n",
    "            (x2 - x1).float() ** 2 + (y2 - y1).float() ** 2)\n",
    "\n",
    "        width = const.width_const * torch.max(wrist_elbow_dist.float(),\n",
    "                                              const.elbow_shoulder_dist_const * elbow_shoulder_dist.float())\n",
    "\n",
    "        x -= width / 2\n",
    "        y -= width / 2\n",
    "\n",
    "        if x < 0:\n",
    "            x = 0\n",
    "        if y < 0:\n",
    "            y = 0\n",
    "\n",
    "        width1 = width\n",
    "        width2 = width\n",
    "\n",
    "        if x + width > const.reshape_w.float():\n",
    "            width1 = const.reshape_w.float() - x\n",
    "        if y + width > const.reshape_h.float():\n",
    "            width2 = const.reshape_h.float() - y\n",
    "\n",
    "        width = torch.min(width1, width2)\n",
    "\n",
    "        if width >= 20:\n",
    "            detect_result.append([int(x), int(y), int(width), is_left])\n",
    "\n",
    "    return detect_result\n",
    "\n",
    "\n",
    "\n",
    "def extracting(resize_imgs, body_model, hand_model, verbose, const):\n",
    "    batch_size = resize_imgs.shape[0]\n",
    "\n",
    "    all_body_peaks = torch.zeros((batch_size, 8, 2), dtype=torch.long).to(const.device)\n",
    "    all_hand_peaks = torch.zeros((batch_size, 2, 21, 2), dtype=torch.long).to(const.device)\n",
    "\n",
    "    imp = SimpleImputer(missing_values=0, strategy='mean')\n",
    "\n",
    "    inputs = torch.flip(resize_imgs, [1])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, outputs = body_model(inputs)\n",
    "    \n",
    "    outputs = F.interpolate(outputs, scale_factor=(const.scale_factor, const.scale_factor))\n",
    "\n",
    "    for idx, heatmap in (tqdm(enumerate(outputs)) if verbose else enumerate(outputs)):\n",
    "        parsing_body_heatmap(all_body_peaks, idx, heatmap[:8], const)\n",
    "\n",
    "    for idx, body_peaks in (tqdm(enumerate(all_body_peaks)) if verbose else enumerate(all_body_peaks)):\n",
    "        hands_list = hand_detect(body_peaks, const)\n",
    "        \n",
    "        for x, y, w, is_left in hands_list:\n",
    "            if x == 0: continue\n",
    "\n",
    "            if is_left:\n",
    "                hand_box = torch.flip(inputs[idx][:, y:y+w, x:x+w], [-1])\n",
    "            else:\n",
    "                hand_box = inputs[idx][:, y:y+w, x:x+w]\n",
    "            \n",
    "            origin_h, origin_w = hand_box.shape[1:]\n",
    "            factor = const.reshape_h / origin_h\n",
    "                \n",
    "            hand_box = F.interpolate(torch.unsqueeze(hand_box, 0), scale_factor=(factor, factor))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                peaks = hand_model(hand_box)\n",
    "\n",
    "            peaks = F.interpolate(peaks, [origin_h, origin_w])\n",
    "            peaks = torch.squeeze(peaks)\n",
    "            \n",
    "            parsing_hand_heatmap(all_hand_peaks[:, 0 if is_left else 1], idx, peaks[:21], const)\n",
    "\n",
    "            hand_peaks = all_hand_peaks[idx, 0 if is_left else 1]\n",
    "            if is_left:\n",
    "                hand_peaks[:, 0] = torch.where(\n",
    "                    hand_peaks[:, 0] == 0, hand_peaks[:, 0], -(hand_peaks[:, 0]-w)+x)\n",
    "                hand_peaks[:, 1] = torch.where(\n",
    "                    hand_peaks[:, 1] == 0, hand_peaks[:, 1], hand_peaks[:, 1]+y)\n",
    "\n",
    "            else:\n",
    "                hand_peaks[:, 0] = torch.where(\n",
    "                    hand_peaks[:, 0] == 0, hand_peaks[:, 0], hand_peaks[:, 0]+x)\n",
    "                hand_peaks[:, 1] = torch.where(\n",
    "                    hand_peaks[:, 1] == 0, hand_peaks[:, 1], hand_peaks[:, 1]+y)\n",
    "                \n",
    "            hand_peaks = hand_peaks.cpu().detach().numpy()\n",
    "            \n",
    "            imp.fit(hand_peaks)\n",
    "            hand_peaks = imp.transform(hand_peaks)\n",
    "\n",
    "            if len(hand_peaks[0]) == 0: \n",
    "                continue\n",
    "\n",
    "            all_hand_peaks[idx, 0 if is_left else 1] = torch.from_numpy(hand_peaks).to(device)\n",
    "\n",
    "    return all_body_peaks.cpu().detach().numpy(), all_hand_peaks.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "\n",
    "const = constant_gpu()\n",
    "const.pendding(device)\n",
    "\n",
    "body_model = BodyposeModel()\n",
    "body_model.load_state_dict(torch.load('./models/body_model.pth'))\n",
    "body_model = body_model.to(device)\n",
    "body_model.eval()\n",
    "body_model(torch.zeros((1, 3, const.reshape_w, const.reshape_h)).to(device))\n",
    "\n",
    "hand_model = HandposeModel()\n",
    "hand_model.load_state_dict(torch.load('./models/hand_model.pth'))\n",
    "hand_model = hand_model.to(device)\n",
    "hand_model.eval()\n",
    "hand_model(torch.zeros((1, 3, const.reshape_w, const.reshape_h)).to(device))\n",
    "\n",
    "\n",
    "def img_to_tensor(img, factor=256., norm=0.5, device=\"cpu\"):\n",
    "    return torch.tensor((np.array(img) / factor) - norm, dtype=torch.float32).transpose(0, 2).transpose(1, 2)\n",
    "\n",
    "\n",
    "def resize_to_tensor(imgs, const):\n",
    "    assert len(imgs) != 0\n",
    "    imgs.sort(key=natural_key)\n",
    "    return torch.cat([\n",
    "        torch.unsqueeze(\n",
    "            img_to_tensor(\n",
    "                Image.open(file)\n",
    "                .resize((const.reshape_w, const.reshape_h))), 0).to(device) for file in imgs], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bodypose(canvas, candidate):\n",
    "    stickwidth = 4\n",
    "    limbSeq = [[2, 3], [2, 6], [3, 4], [4, 5], [6, 7], [7, 8], [2, 9], [9, 10], \\\n",
    "               [10, 11], [2, 12], [12, 13], [13, 14], [2, 1], [1, 15], [15, 17], \\\n",
    "               [1, 16], [16, 18], [3, 17], [6, 18]]\n",
    "\n",
    "    colors = [[255, 0, 0], [255, 85, 0], [255, 170, 0], [255, 255, 0], [170, 255, 0], [85, 255, 0], [0, 255, 0], \\\n",
    "              [0, 255, 85], [0, 255, 170], [0, 255, 255], [0, 170, 255], [0, 85, 255], [0, 0, 255], [85, 0, 255], \\\n",
    "              [170, 0, 255], [255, 0, 255], [255, 0, 170], [255, 0, 85]]\n",
    "    \n",
    "    for idx, (x, y) in enumerate(candidate[0]):\n",
    "        cv2.circle(canvas, (x, y), 4, colors[idx], thickness=-1)\n",
    "            \n",
    "    return canvas\n",
    "\n",
    "\n",
    "def draw_handpose(canvas, all_hand_peaks, show_number=False):\n",
    "    edges = [[0, 1], [1, 2], [2, 3], [3, 4], [0, 5], [5, 6], [6, 7], [7, 8], [0, 9], [9, 10], \\\n",
    "             [10, 11], [11, 12], [0, 13], [13, 14], [14, 15], [15, 16], [0, 17], [17, 18], [18, 19], [19, 20]]\n",
    "    fig = Figure(figsize=plt.figaspect(canvas))\n",
    "\n",
    "    fig.subplots_adjust(0, 0, 1, 1)\n",
    "    fig.subplots_adjust(bottom=0, top=1, left=0, right=1)\n",
    "    bg = FigureCanvas(fig)\n",
    "    ax = fig.subplots()\n",
    "    ax.axis('off')\n",
    "    ax.imshow(canvas)\n",
    "\n",
    "    width, height = ax.figure.get_size_inches() * ax.figure.get_dpi()\n",
    "\n",
    "    for peaks in all_hand_peaks:\n",
    "        for ie, e in enumerate(edges):\n",
    "            if np.sum(np.all(peaks[e], axis=1)==0)==0:\n",
    "                x1, y1 = peaks[e[0]]\n",
    "                x2, y2 = peaks[e[1]]\n",
    "                ax.plot([x1, x2], [y1, y2], color=matplotlib.colors.hsv_to_rgb([ie/float(len(edges)), 1.0, 1.0]))\n",
    "\n",
    "        for i, keyponit in enumerate(peaks):\n",
    "            x, y = keyponit\n",
    "            ax.plot(x, y, 'r.')\n",
    "            if show_number:\n",
    "                ax.text(x, y, str(i))\n",
    "    bg.draw()\n",
    "    canvas = np.fromstring(bg.tostring_rgb(), dtype='uint8').reshape(int(height), int(width), 3)\n",
    "    return canvas\n",
    "\n",
    "\n",
    "def _resize(img, dsize, fx=None, fy=None, anti_aliasing=True):\n",
    "    from skimage.transform import resize\n",
    "    \n",
    "    if fx is None:\n",
    "        return resize(img, (dsize[1], dsize[0]), anti_aliasing, preserve_range=True)\n",
    "    \n",
    "    else:\n",
    "        return resize(img, \n",
    "                      (math.ceil(img.shape[0] * fx), \n",
    "                       math.ceil(img.shape[1] * fy)),\n",
    "                      anti_aliasing, preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = sorted(glob.glob(frame_path + '*'))\n",
    "img = img_list[50:51]\n",
    "\n",
    "tenser = resize_to_tensor(img, const)\n",
    "body_key, hand_key = extracting(tenser, body_model, hand_model, verbose=True, const=const)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "oriImg = cv2.imread(img[0])\n",
    "\n",
    "plt.figure(figsize=(30, 30))\n",
    "oriImg = _resize(oriImg, (656, 368)).astype(np.uint8)\n",
    "\n",
    "canvas = copy.deepcopy(oriImg)\n",
    "\n",
    "canvas = draw_bodypose(canvas, body_key)\n",
    "canvas = draw_handpose(canvas, hand_key[0])\n",
    "\n",
    "plt.figure(figsize=(30, 30))\n",
    "plt.imshow(canvas[:, :, [2, 1, 0]])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_pose_(canvas, all_hand_peaks, all_body_peaks):\n",
    "    \n",
    "    #body\n",
    "    stickwidth = 4\n",
    "    limbSeq = [[2, 3], [2, 6], [3, 4], [4, 5], [6, 7], [7, 8], [2, 9], [9, 10], \\\n",
    "               [10, 11], [2, 12], [12, 13], [13, 14], [2, 1], [1, 15], [15, 17], \\\n",
    "               [1, 16], [16, 18], [3, 17], [6, 18]]\n",
    "\n",
    "    colors = [[255, 0, 0], [255, 85, 0], [255, 170, 0], [255, 255, 0], [170, 255, 0], [85, 255, 0], [0, 255, 0], \\\n",
    "              [0, 255, 85], [0, 255, 170], [0, 255, 255], [0, 170, 255], [0, 85, 255], [0, 0, 255], [85, 0, 255], \\\n",
    "              [170, 0, 255], [255, 0, 255], [255, 0, 170], [255, 0, 85]]\n",
    "    \n",
    "    for idx, (x, y) in enumerate(all_body_peaks[0]):\n",
    "        cv2.circle(canvas, (x, y), 4, colors[idx], thickness=-1)\n",
    "        cv2.line(canvas, (x, y), (x+1, y+1), color = (255, 255, 255), thickness=2)\n",
    "    \n",
    "    \n",
    "    #hand\n",
    "    edges = [[0, 1], [1, 2], [2, 3], [3, 4], [0, 5], [5, 6], [6, 7], [7, 8], [0, 9], [9, 10], \\\n",
    "             [10, 11], [11, 12], [0, 13], [13, 14], [14, 15], [15, 16], [0, 17], [17, 18], [18, 19], [19, 20]]\n",
    "                 \n",
    "    fig = Figure(figsize=plt.figaspect(canvas))\n",
    "    \n",
    "    for idx, (x, y) in enumerate(all_hand_peaks[0]):\n",
    "        cv2.line(canvas, (x, y), (x+1, y+1), color = (255, 255, 255), thickness=2)\n",
    "                 \n",
    "\n",
    "    fig.subplots_adjust(0, 0, 1, 1)\n",
    "    fig.subplots_adjust(bottom=0, top=1, left=0, right=1)\n",
    "    bg = FigureCanvas(fig)\n",
    "    ax = fig.subplots()\n",
    "    ax.axis('off')\n",
    "    ax.imshow(canvas)\n",
    "\n",
    "    width, height = ax.figure.get_size_inches() * ax.figure.get_dpi()\n",
    "\n",
    "    for peaks in all_hand_peaks:\n",
    "        for ie, e in enumerate(edges):\n",
    "            if np.sum(np.all(peaks[e], axis=1)==0)==0:\n",
    "                x1, y1 = peaks[e[0]]\n",
    "                x2, y2 = peaks[e[1]]\n",
    "                ax.plot([x1, x2], [y1, y2], color=matplotlib.colors.hsv_to_rgb([ie/float(len(edges)), 1.0, 1.0]))\n",
    "                cv2.line(canvas, (x1, x2), (x2, y2), color = (255, 255, 255), thickness=2)\n",
    "\n",
    "        for i, keyponit in enumerate(peaks):\n",
    "            x, y = keyponit\n",
    "            ax.plot(x, y, 'r.')\n",
    "            if show_number:\n",
    "                ax.text(x, y, str(i))\n",
    "    bg.draw()\n",
    "    canvas = np.fromstring(bg.tostring_rgb(), dtype='uint8').reshape(int(height), int(width), 3)\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
